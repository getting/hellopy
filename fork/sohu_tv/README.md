问题1: 爬取tv.sohu.com的页面, 提取视频相关信息，不可用爬虫框架完成

需求:

做到最大可能的页面覆盖率
选择重要的信息进行存储
选择合适的数据存储方式，便于后续使用
可通过参数限制要抓取视频信息的数目
要用多线程方式完成抓取
反防抓取策略
*分布式支持
*崩溃后进度恢复
星号部分为加分项, 可只给出设计思路 ...





1、采用广度优先算法，从一个入口(首页）地址开始，将地址加入队列，并存储到已抓取的url集合中，将存储在队列中的地址取出并找出对应页面全部url地址，
将得到的地址与已经抓取的url集合进行对比，如果url集合中尚不存在，加入集合，并加入队列。重复操作，知道寻找到所有链接。

对于得到的链接如果符合视频页规则，则加入视频信息提取队列，进行视频信息提取。

目前的程序在采集url的同时进行视频信息的提取，对于速度难以控制，或许将两者分开进行效果会更好些。

2、

只抓取单独的视频页，不抓取分类和剧集等页面信息


对于视频页主要有两种类型：

官方发布的视频：http://tv.sohu.com/20140304/n395970803.shtml
日期 + 编号

用户上传的视频：http://my.tv.sohu.com/us/200430155/63582287.shtml
用户id + 编号


body部分不同频道结构不够统一，对于一般的视频信息采集，页面head部分的信息已经足够丰富。如果需要更详尽的信息大概主要可从下面这些片段提取信息。

    <div class="infoBox cfix  id=info">
    <div class="info info-con">
    <div class="area cfix" id="content">




3、

数据采用MongoD存储

主要有两个集合：
url   存储已经收集到的地址：主要用于比对和去重，防止重复抓取
    url: 原始链接地址
    id: 原始链接地址的hash值，用于快速比对

tv    用于存储获取的视频信息

数据存储在MongoDB，为提高性能对于已经抓取的url可以用redis存储和进行去重比对。广度优先可能会采集很多重读的url在数据库中已知url变多时，从中
进行查询和对比可能会很慢，可以将类似首页等最容易出现重复的部分，单独存储在一个列表中，在去重对比时先对比这个小的列表，如果重复则不再需要查询数据库。


4、可通过参数限制要抓取视频信息的数目
参数可以通过 video_num 设置


5、反防抓取策略：
通过设置设置User-Agent等实现简单的反防抓取，如果需要可以添加代理设置。


5、分布式支持

可以利用MongoDB的分片？
按url类型，用户上传，和光放上传，或按照时期进行切分，分布到不同的机器上处理


6、崩溃后的恢复？

所有已经遍历的地址存储在数据库中，在一个地址被成功处理后可以做一条标记，在崩溃后将未标记部分重新加入队列，继续进行搜索。


##爬虫测试

在4小时内抓取独立url地址超过10万，视频信息条目超过8万。数据参见data目录。


## 遇到的问题：
指定参数限制要抓取视频信息的数目，在达到抓取数目时无法自行终止。





## 视频总数估算

site:tv.sohu.com

Baidu: 83,100,000
Google：17,300,000

30,000,000 ?
